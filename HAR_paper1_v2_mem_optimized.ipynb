{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR_paper1_v2_mem_optimized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwaksharDeb/Activity-recognition/blob/master/HAR_paper1_v2_mem_optimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyySE82xZ0cU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7117c4e4-02d8-48ad-c0f9-b5b258aa7652"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO0vZIpuEFIk",
        "colab_type": "text"
      },
      "source": [
        "# Importing dependecies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfT91Bst1KPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import csv\n",
        "import array\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from numpy import savetxt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import scipy.stats as stats\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from math import sqrt\n",
        "import math\n",
        "\n",
        "# for garbage collection\n",
        "import gc"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsJvSwV0EJuH",
        "colab_type": "text"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Wo5uGT_T3u",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0479854e-9f88-4880-b300-9c0080fbc4c3"
      },
      "source": [
        "#@title Load datasets from folder\n",
        "#@markdown Outputs a list of all csv files in folder into <i> data_list </i>\n",
        "\n",
        "folder_path = \"/content/drive/My Drive/nurse care data/swakshar\" #@param {type : \"string\"}\n",
        "\n",
        "import os\n",
        "\n",
        "data_files = os.listdir(folder_path)\n",
        "data_list = []\n",
        "\n",
        "for data_file in data_files:\n",
        "    full_file_name = os.path.join(folder_path, data_file)\n",
        "\n",
        "    data_list.append(pd.read_csv(full_file_name))\n",
        "    print(f\"{full_file_name} read and appended.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/nurse care data/swakshar/final_field_user04_dataset.csv read and appended.\n",
            "/content/drive/My Drive/nurse care data/swakshar/lab data localized.csv read and appended.\n",
            "/content/drive/My Drive/nurse care data/swakshar/final_field_user51_dataset.csv read and appended.\n",
            "/content/drive/My Drive/nurse care data/swakshar/final_field_user07_dataset.csv read and appended.\n",
            "/content/drive/My Drive/nurse care data/swakshar/final_field_user38_dataset.csv read and appended.\n",
            "/content/drive/My Drive/nurse care data/swakshar/final_field_user18_dataset.csv read and appended.\n",
            "/content/drive/My Drive/nurse care data/swakshar/final_field_user08_dataset.csv read and appended.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v63aGx_78pCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.concat(data_list, ignore_index=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaCzxu7p8v1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del data_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdN-d87rdohb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "dbd43079-651d-4f84-fb72-aecfae8b144d"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>act_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.221</td>\n",
              "      <td>7.776</td>\n",
              "      <td>6.366</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.455</td>\n",
              "      <td>7.125</td>\n",
              "      <td>5.890</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.455</td>\n",
              "      <td>7.125</td>\n",
              "      <td>5.890</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.574</td>\n",
              "      <td>6.205</td>\n",
              "      <td>6.653</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.260</td>\n",
              "      <td>5.171</td>\n",
              "      <td>7.721</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867772</th>\n",
              "      <td>3.447</td>\n",
              "      <td>6.818</td>\n",
              "      <td>4.217</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867773</th>\n",
              "      <td>3.447</td>\n",
              "      <td>6.818</td>\n",
              "      <td>4.217</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867774</th>\n",
              "      <td>-0.306</td>\n",
              "      <td>6.857</td>\n",
              "      <td>6.618</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867775</th>\n",
              "      <td>-0.306</td>\n",
              "      <td>6.857</td>\n",
              "      <td>6.618</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867776</th>\n",
              "      <td>-0.727</td>\n",
              "      <td>8.236</td>\n",
              "      <td>6.456</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1867777 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             x      y      z  act_id\n",
              "0       -2.221  7.776  6.366     5.0\n",
              "1        1.455  7.125  5.890     5.0\n",
              "2        1.455  7.125  5.890     5.0\n",
              "3        0.574  6.205  6.653     5.0\n",
              "4        2.260  5.171  7.721     5.0\n",
              "...        ...    ...    ...     ...\n",
              "1867772  3.447  6.818  4.217    12.0\n",
              "1867773  3.447  6.818  4.217    12.0\n",
              "1867774 -0.306  6.857  6.618    12.0\n",
              "1867775 -0.306  6.857  6.618    12.0\n",
              "1867776 -0.727  8.236  6.456    12.0\n",
              "\n",
              "[1867777 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLDhx7FJEQzE",
        "colab_type": "text"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGzc9PGf12TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Data processing\"\"\"\n",
        "X = dataset.iloc[:, [0, 1, 2]].values\n",
        "Y = dataset.iloc[:, 3].values\n",
        "Y = Y - 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjtZfDrEETiD",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYm3xTobEXtQ",
        "colab_type": "text"
      },
      "source": [
        "we just use scaling for data augmentation. The minority classes are scaled and added to the original data to make the original data balance. Our assumption is that, if we scale a signal it still represent the same activity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cSKhDMiBcxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation\n",
        "scalling_factor = [0.3,0.5,0.7,0.8,1.2,1.5,2]\n",
        "\n",
        "for scal in scalling_factor:\n",
        "    X_1_scal = X[np.where(Y==1)]*scal\n",
        "    label_1 = Y[np.where(Y==1)]\n",
        "    X_2_scal = X[np.where(Y==2)]*scal\n",
        "    label_2 = Y[np.where(Y==2)]\n",
        "    X_5_scal = X[np.where(Y==5)]*scal\n",
        "    label_5 = Y[np.where(Y==5)]\n",
        "    X_7_scal = X[np.where(Y==7)]*scal\n",
        "    label_7 = Y[np.where(Y==7)]\n",
        "    X_8_scal = X[np.where(Y==8)]*scal\n",
        "    label_8 = Y[np.where(Y==8)]\n",
        "    X_9_scal = X[np.where(Y==9)]*scal\n",
        "    label_9 = Y[np.where(Y==9)]\n",
        "    X_10_scal = X[np.where(Y==10)]*scal\n",
        "    label_10 = Y[np.where(Y==10)]\n",
        "    X = np.concatenate((X, X_1_scal,X_2_scal,X_5_scal,X_7_scal,X_8_scal,X_9_scal,X_10_scal))\n",
        "    Y = np.concatenate((Y, label_1,label_2, label_5, label_7, label_8, label_9, label_10))\n",
        "\n",
        "scalling_factor = [0.5,2]\n",
        "\n",
        "for scal in scalling_factor:\n",
        "    X_3_scal = X[np.where(Y==3)]*scal\n",
        "    label_3 = Y[np.where(Y==3)]\n",
        "    X_11_scal = X[np.where(Y==11)]*scal\n",
        "    label_11 = Y[np.where(Y==11)]\n",
        "    X = np.concatenate((X, X_3_scal, X_11_scal))\n",
        "    Y = np.concatenate((Y, label_3, label_11))\n",
        "\n",
        "scalling_factor = [0.3,0.5,1.5,2]\n",
        "\n",
        "for scal in scalling_factor:\n",
        "    X_0_scal = X[np.where(Y==0)]*scal\n",
        "    label_0 = Y[np.where(Y==0)]\n",
        "    X_6_scal = X[np.where(Y==6)]*scal\n",
        "    label_6 = Y[np.where(Y==6)]\n",
        "    X = np.concatenate((X, X_0_scal, X_6_scal))\n",
        "    Y = np.concatenate((Y, label_0, label_6))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znZLW9czCaqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "garbage = [X_0_scal, X_1_scal, X_2_scal, X_3_scal, X_5_scal, X_6_scal, X_7_scal, X_8_scal, X_9_scal, X_10_scal, X_11_scal, label_0, label_1, label_2, label_3, label_5, label_6, label_7, label_8, label_9, label_10, label_11]\n",
        "\n",
        "del garbage"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOStAJAVF3uE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f7e77e8-a146-4a7e-ff8d-ffc5471863dc"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi8aVSwmEwv3",
        "colab_type": "text"
      },
      "source": [
        "## Low pass filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW-Q1iM2EgEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def low_pass_filter(input):\n",
        "    low_pass_data = np.zeros((input.shape))\n",
        "\n",
        "    for i in range(len(input)):\n",
        "        for j in range(input.shape[1]):\n",
        "            if i == 0:\n",
        "                low_pass_data[i][j] = input[i][j]\n",
        "            else:\n",
        "                low_pass_data[i][j] = 0.8*input[i-1][j] + (1-0.8)*input[i][j]\n",
        "\n",
        "    return low_pass_data\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKRPp1BzEzbl",
        "colab_type": "text"
      },
      "source": [
        "## Frame preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzP7YBIr17qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Fs = 4\n",
        "POLLING_RATE = 4 #Hz\n",
        "FRAME_SIZE = Fs*20 # 80 # 20 seconds of data\n",
        "HOP_SIZE =  Fs*10\n",
        "\n",
        "def get_frames(df, label_data):\n",
        "    N_FEATURES = 3\n",
        "\n",
        "    frames = []\n",
        "    labels = []\n",
        "    for i in range(0, len(df) - FRAME_SIZE, HOP_SIZE):\n",
        "        value = df[i:i + FRAME_SIZE, :]\n",
        "\n",
        "        # Retrieve the most often used label in this segment\n",
        "        label = stats.mode(label_data[i: i + FRAME_SIZE])[0][0]\n",
        "        frames.append([value])\n",
        "        labels.append(label)\n",
        "\n",
        "    # Bring the segments into a better shape\n",
        "    frames = np.asarray(frames).reshape(-1, FRAME_SIZE, N_FEATURES)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    return frames, labels\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmF6XZtME3ZE",
        "colab_type": "text"
      },
      "source": [
        "## Feature calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw_YwRvpE_Ib",
        "colab_type": "text"
      },
      "source": [
        "### Define all feature calculation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGngQIN6EoBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_mean(low_pass_frame):\n",
        "    return np.mean(low_pass_frame, axis=1)\n",
        "\n",
        "def calculate_std(low_pass_frame):\n",
        "    return np.std(low_pass_frame, axis=1)\n",
        "\n",
        "def calculate_rms(low_pass_frame):\n",
        "    rms_x = []\n",
        "    rms_y = []\n",
        "    rms_z = []\n",
        "\n",
        "    values = [0, 0, 0]\n",
        "    no_frames, frame_length, no_axes = low_pass_frame.shape\n",
        "    for i in range(no_frames):\n",
        "        for j in range(frame_length):\n",
        "            for k in range(no_axes):\n",
        "                values[k] += (low_pass_frame[i][j][k] ** 2)\n",
        "\n",
        "        values = [sqrt(value / frame_length) for value in values]\n",
        "\n",
        "        rms_x.append(values[0])\n",
        "        rms_y.append(values[1])\n",
        "        rms_z.append(values[2])\n",
        "\n",
        "        values = [0, 0, 0]\n",
        "\n",
        "    return rms_x, rms_y, rms_z\n",
        "\n",
        "def calculate_vec_length(frame):\n",
        "    lengths = []\n",
        "\n",
        "    nx, ny, nz = frame.shape\n",
        "    acc_vector = np.reshape(frame, (nx, ny * nz))\n",
        "\n",
        "    for i in range(acc_vector.shape[0]):\n",
        "        length = 0\n",
        "        count = 0\n",
        "\n",
        "        for j in range(acc_vector.shape[1]):\n",
        "            length += acc_vector[i][j] ** 2\n",
        "            count += 1\n",
        "\n",
        "            if count == 3:\n",
        "                lengths.append(sqrt(length))\n",
        "                length = 0\n",
        "                count = 0\n",
        "\n",
        "    return lengths\n",
        "\n",
        "def calculate_avc(lengths):\n",
        "    avc = []\n",
        "\n",
        "    for i in range(0, len(lengths), FRAME_SIZE):\n",
        "        value = 0\n",
        "        iterable = lengths[i:i+FRAME_SIZE]\n",
        "        for j in range(len(iterable) - 1, 1, -1):\n",
        "            value += abs(iterable[j] - iterable[j - 1])\n",
        "\n",
        "        value /= (FRAME_SIZE / POLLING_RATE)\n",
        "        avc.append(value)\n",
        "\n",
        "    return avc\n",
        "\n",
        "def calculate_max_min(lengths):\n",
        "    max_min = []\n",
        "    for i in range(0, len(lengths), FRAME_SIZE):\n",
        "        iterable = lengths[i:i+FRAME_SIZE]\n",
        "\n",
        "        max_min.append(max(iterable) - min(iterable))\n",
        "\n",
        "    return max_min\n",
        "\n",
        "def calculate_angles(low_pass_frame):\n",
        "    angle = np.zeros(low_pass_frame.shape)\n",
        "\n",
        "    no_frames, frame_length, no_axes = angle.shape\n",
        "    length = 0\n",
        "    for i in range(no_frames):\n",
        "        for j in range(frame_length):\n",
        "            for k in range(no_axes):\n",
        "                length += low_pass_frame[i, j, k] ** 2\n",
        "            length = sqrt(length)\n",
        "\n",
        "            if length == 0:\n",
        "                print(\"length is zero in index row= \", i, \"column= \", j)\n",
        "            else:\n",
        "                angle_x = math.acos(low_pass_frame[i, j, 0] / length)\n",
        "                angle_y = math.acos(low_pass_frame[i, j, 1] / length)\n",
        "                angle_z = math.acos(low_pass_frame[i, j, 2] / length)\n",
        "                angle[i][j][0] = angle_x\n",
        "                angle[i][j][1] = angle_y\n",
        "                angle[i][j][2] = angle_z\n",
        "\n",
        "    nx, ny, nz = angle.shape\n",
        "\n",
        "    return np.reshape(angle, (nx, ny * nz))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zseLnYMQ9r2",
        "colab_type": "text"
      },
      "source": [
        "### Define input vector calculating function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88gT5JOhRCnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_vector(input_X, input_Y):\n",
        "    low_pass_X = low_pass_filter(input_X)\n",
        "\n",
        "    row_frame, row_labels = get_frames(input_X, input_Y)\n",
        "    low_pass_frame, low_pass_labels = get_frames(low_pass_X, input_Y)\n",
        "\n",
        "    mean = calculate_mean(low_pass_frame)\n",
        "    std = calculate_std(low_pass_frame)\n",
        "    rms_x, rms_y, rms_z = calculate_rms(low_pass_frame)\n",
        "    lengths = calculate_vec_length(row_frame)\n",
        "    avc = calculate_avc(lengths)\n",
        "    max_min = calculate_max_min(lengths)\n",
        "    angles = calculate_angles(low_pass_frame)\n",
        "\n",
        "    input_vector = np.zeros((row_frame.shape[0], angles.shape[1] + 11))\n",
        "    for i in range(input_vector.shape[0]):\n",
        "        input_vector[i][0] = mean[i][0]\n",
        "        input_vector[i][1] = mean[i][1]\n",
        "        input_vector[i][2] = mean[i][2]\n",
        "        input_vector[i][3] = std[i][0]\n",
        "        input_vector[i][4] = std[i][1]\n",
        "        input_vector[i][5] = std[i][2]\n",
        "        input_vector[i][6] = rms_x[i]\n",
        "        input_vector[i][7] = rms_y[i]\n",
        "        input_vector[i][8] = rms_z[i]\n",
        "        input_vector[i][9] = max_min[i]\n",
        "        input_vector[i][10] = avc[i]\n",
        "\n",
        "    for i in range(angles.shape[0]):\n",
        "        for j in range(angles.shape[1]):\n",
        "            input_vector[i][j+11] = angles[i][j]\n",
        "\n",
        "    return input_vector, row_labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOcALOcjbe29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_vector, final_labels = get_input_vector(X, Y)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "furzoe0dE8Am",
        "colab_type": "text"
      },
      "source": [
        "# Standarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU3_g1iz2ML4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = StandardScaler()\n",
        "input_vector = sc.fit_transform(input_vector)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRhtdueQFAjp",
        "colab_type": "text"
      },
      "source": [
        "# Train Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty_Fy4U9beWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, X_val, y_train, y_val = train_test_split(input_vector, final_labels, test_size=0.2, stratify=final_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIUflLCXIakv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "og_X = dataset.iloc[:, [0, 1, 2]].values\n",
        "og_Y = (dataset.iloc[:, 3].values) - 1\n",
        "\n",
        "length = round(len(og_X) * 0.2)\n",
        "start_point = np.random.randint(0, len(og_X) - length)\n",
        "end_point = start_point + length + 1\n",
        "\n",
        "og_X = og_X[start_point:end_point]\n",
        "og_Y = og_Y[start_point:end_point]\n",
        "\n",
        "X_train, y_train = input_vector, final_labels\n",
        "X_val, y_val = get_input_vector(og_X, og_Y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcWnYyErllV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = sc.fit_transform(X_val)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DETuA1BKFDHf",
        "colab_type": "text"
      },
      "source": [
        "# Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWtC4-gSFF6k",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR7hOhV22XQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=32, activation='relu', input_shape=(X_train.shape[1], )))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(units=324, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(units=12, activation='softmax'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOcsqzN92Y3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIHGmDM52c9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "25cc4997-075e-45d4-a0cf-5a03b5a0a26e"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val), verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10544/10544 [==============================] - 19s 2ms/step - loss: 1.1930 - accuracy: 0.6291 - val_loss: 4.0354 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "10544/10544 [==============================] - 18s 2ms/step - loss: 0.9831 - accuracy: 0.6821 - val_loss: 5.0782 - val_accuracy: 1.0710e-04\n",
            "Epoch 3/50\n",
            "10544/10544 [==============================] - 19s 2ms/step - loss: 0.8886 - accuracy: 0.7125 - val_loss: 5.7026 - val_accuracy: 2.1420e-04\n",
            "Epoch 4/50\n",
            "10544/10544 [==============================] - 25s 2ms/step - loss: 0.8287 - accuracy: 0.7318 - val_loss: 5.2507 - val_accuracy: 1.0710e-04\n",
            "Epoch 5/50\n",
            "10544/10544 [==============================] - 18s 2ms/step - loss: 0.7877 - accuracy: 0.7458 - val_loss: 6.6132 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "10544/10544 [==============================] - 17s 2ms/step - loss: 0.7548 - accuracy: 0.7565 - val_loss: 4.3797 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "10544/10544 [==============================] - 17s 2ms/step - loss: 0.7286 - accuracy: 0.7654 - val_loss: 5.5818 - val_accuracy: 1.0710e-04\n",
            "Epoch 8/50\n",
            "10544/10544 [==============================] - 19s 2ms/step - loss: 0.7092 - accuracy: 0.7722 - val_loss: 6.0001 - val_accuracy: 1.0710e-04\n",
            "Epoch 9/50\n",
            "10544/10544 [==============================] - 18s 2ms/step - loss: 0.6920 - accuracy: 0.7778 - val_loss: 5.5763 - val_accuracy: 1.0710e-04\n",
            "Epoch 10/50\n",
            "10544/10544 [==============================] - 18s 2ms/step - loss: 0.6780 - accuracy: 0.7825 - val_loss: 5.6394 - val_accuracy: 0.0026\n",
            "Epoch 11/50\n",
            "10544/10544 [==============================] - 18s 2ms/step - loss: 0.6652 - accuracy: 0.7865 - val_loss: 6.6346 - val_accuracy: 4.2840e-04\n",
            "Epoch 12/50\n",
            "10544/10544 [==============================] - 18s 2ms/step - loss: 0.6553 - accuracy: 0.7904 - val_loss: 6.1547 - val_accuracy: 2.1420e-04\n",
            "Epoch 13/50\n",
            "10544/10544 [==============================] - 19s 2ms/step - loss: 0.6466 - accuracy: 0.7934 - val_loss: 5.4568 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "10544/10544 [==============================] - 20s 2ms/step - loss: 0.6387 - accuracy: 0.7959 - val_loss: 7.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "10544/10544 [==============================] - 18s 2ms/step - loss: 0.6309 - accuracy: 0.7986 - val_loss: 8.5424 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "10544/10544 [==============================] - 21s 2ms/step - loss: 0.6251 - accuracy: 0.8005 - val_loss: 7.5231 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "10544/10544 [==============================] - 20s 2ms/step - loss: 0.6183 - accuracy: 0.8032 - val_loss: 9.7988 - val_accuracy: 2.1420e-04\n",
            "Epoch 18/50\n",
            " 5364/10544 [==============>...............] - ETA: 8s - loss: 0.6120 - accuracy: 0.8047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c2b785693944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mincorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m       raise ValueError(\n\u001b[1;32m    577\u001b[0m           \u001b[0;34m\"Arguments and signature arguments do not match. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Wr4r8o2fmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkS_HoEF2hqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_ = np.zeros((y_pred.shape[0]))\n",
        "for i in range(y_pred.shape[0]):\n",
        "    y_pred_[i] = np.argmax(y_pred[i,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acMVWjaE2i5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_pred_, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_1xombvxHWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzxlzsAS2lAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_val, y_pred_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99fq6w9a2mS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "per_class_accuracy = {}\n",
        "for i in range(cm.shape[0]):\n",
        "    accuracy = cm[i,i]/sum(cm[i,:])\n",
        "    per_class_accuracy[i] = accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8YrJNlISwG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "per_class_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}