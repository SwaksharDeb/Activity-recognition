{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "data_preprocessing_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwaksharDeb/Activity-recognition/blob/master/data_preprocessing_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwTPVQAuw25g",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download and extract the dataset\n",
        "\n",
        "URL = \"https://ieee-dataport.s3.amazonaws.com/open/11167/Training.zip?response-content-disposition=attachment%3B%20filename%3D%22Training.zip%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJOHYI4KJCE6Q7MIQ%2F20200616%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200616T082632Z&X-Amz-SignedHeaders=Host&X-Amz-Expires=86400&X-Amz-Signature=945354b7acb38f2172b8978a73ceffbf5943e91a14442c7314dbb666430fb079\" #@param {type : \"string\"} \n",
        "savepath = \"Training.zip\" #@param {type : 'string'}\n",
        "extractpath = \"/content/dataset/\" #@param {type : 'string'}\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "\n",
        "if not os.path.isfile(savepath):\n",
        "  urlretrieve(URL, savepath)\n",
        "with ZipFile(savepath, 'r') as zip_file:\n",
        "  zip_file.extractall(extractpath)\n",
        "\n",
        "!rm -rf /content/sample_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtxlnIPX3mUr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install Dependencies\n",
        "from google.colab import files\n",
        "\n",
        "in_file = files.upload()\n",
        "\n",
        "if len(in_file.keys()) == 1:\n",
        "  for fn in in_file.keys():\n",
        "    requirement = \"/content/\" + str(fn)\n",
        "\n",
        "!pip install -r $requirement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615YqgUK3ItS",
        "colab_type": "text"
      },
      "source": [
        "<h1> Import Dependencies </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCBdx0Jqv80p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from fastdtw import fastdtw\n",
        "#from dtaidistance import dtw\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import datetime\n",
        "import dateutil\n",
        "import csv\n",
        "import array\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from numpy import savetxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD4eyNFMv80z",
        "colab_type": "text"
      },
      "source": [
        "# Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpx-YjFVv802",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lab data\n",
        "lab_accel_dataset = pd.read_csv(\"/content/dataset/Lab/bigact_raw_lab_acc.csv\", na_filter=False, parse_dates=[1], infer_datetime_format=True, date_parser=lambda col : pd.to_datetime(col, utc=True))\n",
        "lab_label_dataset = pd.read_csv(\"/content/dataset/Lab/labels_lab_2users.csv\", na_filter=False, parse_dates=[2, 3], infer_datetime_format=True, date_parser=lambda col : pd.to_datetime(col, utc=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx1Z9guhv809",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(lab_accel_dataset)\n",
        "print(lab_label_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KTDvLc4Te3y",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqJ5FWorYscK",
        "colab_type": "text"
      },
      "source": [
        "<h3> Sort the values according to datetime </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIBur-GqTbvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab_accel_dataset = pd.DataFrame.sort_values(lab_accel_dataset, ['datetime'], ignore_index=True)\n",
        "lab_label_dataset = pd.DataFrame.sort_values(lab_label_dataset, ['start', 'finish'], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGtDane5hBcq",
        "colab_type": "text"
      },
      "source": [
        "<h3> Truncate rows from accelerometer dataset whose datetime that do not correspond with label dataset datetime </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWGCXC31hQ_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab_label_first_entry = lab_label_dataset.iloc[0].loc['start']\n",
        "lab_label_last_entry = lab_label_dataset.iloc[-1].loc['start']\n",
        "\n",
        "trunc_lab_accel_dataset = lab_accel_dataset[lab_accel_dataset['datetime'] >= lab_label_first_entry]\n",
        "trunc_lab_accel_dataset = trunc_lab_accel_dataset[trunc_lab_accel_dataset['datetime'] <= lab_label_last_entry]\n",
        "trunc_lab_accel_dataset.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khXVe3xZzPSN",
        "colab_type": "text"
      },
      "source": [
        "<h3> Extract accelerometer data that corresponds to label datetime </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp-3QN9pzlER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_aligned_dataset = []\n",
        "\n",
        "for i in lab_label_dataset.index.values:\n",
        "  start_date = lab_label_dataset.at[i, 'start']\n",
        "  end_date = lab_label_dataset.at[i, 'finish']  \n",
        "  user_id = lab_label_dataset.at[i, 'user_id']\n",
        "\n",
        "  mask = ((trunc_lab_accel_dataset['datetime']  >= start_date) & (trunc_lab_accel_dataset['datetime'] <= end_date) & (trunc_lab_accel_dataset['user_id'] == user_id))\n",
        "  \n",
        "  search_dataset = trunc_lab_accel_dataset.loc[mask].loc[:, ['user_id', 'x', 'y', 'z']]\n",
        "  if not search_dataset.empty:\n",
        "    act_series = pd.Series(lab_label_dataset.at[i, 'act_id']).repeat(search_dataset.shape[0])\n",
        "    # must reset index for concat to succeed\n",
        "    act_series.reset_index(drop=True, inplace=True)\n",
        "    search_dataset.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    chunk = pd.concat([search_dataset, act_series], ignore_index=True, axis=1)\n",
        "    final_aligned_dataset.append(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggxpLKZIqFbC",
        "colab_type": "text"
      },
      "source": [
        "<h3> Generate aligned dataframe </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCZBnLauqJpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_aligned_dataset = pd.concat(final_aligned_dataset)\n",
        "final_aligned_dataset.columns = ['user_id', 'x', 'y', 'z', 'act_id']\n",
        "final_aligned_dataset.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-E5jaKkqBNi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Save aligned data as csv\n",
        "\n",
        "savepath = \"/content/processed\" #@param {type : 'string'}\n",
        "savename = \"final_lab_dataset.csv\" #@param {type : 'string'}\n",
        "\n",
        "import os\n",
        "os.makedirs(savepath, exist_ok=True)\n",
        "\n",
        "complete_savename = savepath + \"/\" + savename\n",
        "final_aligned_dataset.to_csv(complete_savename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}